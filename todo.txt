### TODO

* buffer overrun > 1024 tokens
* change {"%%"} into something more typeable
* volume threshold should be sampled continously
* add main.wafl
* create errors within parser
   * dependency does not exist
   * . is allowes in dependency, / is not

* rules should be added and removed

This and next week:
 /* rules in folder
 * distill gpt2 from gpt-JT onto the CoQA dataset

First week of the year:
 /* Make test conversations work
 * Debugging with picture as output

Second week of the year:
 * User-defined events
 * Scheduler

Third week of the year:
 * Refactoring
 * Write up docs

Fourth week:
 * Write demo paper


/* rules and functions should be in a folder.
/  * Think about ability to install

/* add ability to create rules through text "->"
* main conversation loop should be scheduler
  * Add functions that can trigger rules

* InferenceAnswerer can be broken down into simpler answerer
  * within backward inference there is the need for an answerer (when tasks are interrupted)

* Do lists as hard-coded
* y/n questions are never searched in working memory. Is this the right behavior?
/* test_testcases blocks the tests. RESOLVE THIS!!
* fine tune entailer to the tasks in this systems (the bot says: "", the user asks ""...)
* functions use inference from depth_level = 1. This can induce infinite recursion

* if query is not question and answer is False then the system should say "I cannot do it because"
   * After because there should be the answer to the bot asking itself why
   * The way to do it is to have a narrator connected to the logs
   * you need better readable logs
   * you need a way to translate the logs into a coherent text
   * THIS WILL ADD INTROSPECTION!!

* move all thresholds to variables.py
* rules are sorted by retriever but not by entailer!! Do that

* add error detection in parser.
  * for example ( without a closing ). same for {



/* entailment should be :- instead of <-
/* take entailer and qa out of the __init__ in entailer.py and qa.py
/* implement functions within each dependency
/* remove Batches output in prediction
/* fact retrieval should work in python space as well
/* y/n questions should only accept yes or no (and loop if there is something else)
/* Why does remember not work??!!!
/* separate items added to list with "and"
/* The same answer cannot belong to more than one question in the same task! (it's an approx but needed)
/* Create answering class on top of the conversation
/  * create arbiter class
/    * This should solve the test_executables failing tests
/  * is the dialogue part really needed? if not, you can use a simple qa system

/* Use entailer for common sense? Creak sense does not work very well
/* Make infinite recursion impossible (set max limit or check for repetitions)
/* Do the conversational memory (start with test_working_memory.py)
/ * done but you need to refine the interaction with the narrator class (events are splitted manually in qa.py)
/    * RUN TESTS!!!
/    * START WITH test_conversation (many tests are failing)
/        * The issue is in "the user says" (line 85 in qa.py)
/            - The system should be able to understand if the the user is speaking or the user
/            - possibly if the question is from the user (like in working memory) add "user says"
/            - what would you add when the fact comes from the knowledge base?
/                - should you change the hypothesys "when -> says?" (line 91 and 101)
/
/    * USE LOGGER IN CONVERSATION() TO SPEED UP DEBUGGING!
/* numbers in speaker should be translated to English
/* remove computer as first word
/* Confidence in listener results
/* lists should filter the items
/* a list cannot contain itself, you should check the name
/* Yes/No questions should be more flexible
/* voice thresholds should be in config (write test about them)
/* ADD VERSION NUMBER WHEN STARTING UP
/* check tests.test_working_memory.TestWorkingMemory.test_working_memory_works_for_yes_questions
/* computer name triggers a "faulty" sound

/* functions.py need a more clever way of handling hidden arguments
  - should all functions have a hidden arg?
  - make it possible to have more files

* use different voice model (this one from hf?  )

* speech to text
    - use your own beam decoder + n-gram to improve quality
    - use newer model?
    - filter out filler sounds

* Unify conversation/utils.py "the user says/asks" and the presupposition replace "to the bot" in entailer.py

* Detect who is talking to whom. Some rules can only be activated by the user speaking to the bot
    - Use get_sequence_probability_given_prompt()

* add in knowledge facts about "the user". You don't need to remember everything that is said

* Is there a need for a "Main Task" ? One that oversees everything?

* Python hooks need to be in a class, like with Tests

* rms threshold should be average of background noise
* add delete last item


* Change the speaker voice

* Create unit tests for conversation activation/deactivation

* The answer to the question can be found in the conversation from the bot.
  The bot can speak to itself and then answer the user

* train your own retriever using the conversations in dailydialogue? MAYBE NOT
* If the query is a question YOU NEED A QA RETRIEVER. take MULTI_QA instead of MSMARCO
  - also if the rule.effect is a question


* If a function calls another one within functions.py then there is an argument missing! inference is not there in the code

*yes/no questions should *never* trigger an interruption.
 It's not just yes/no answers, the deal is with the question!



* Select by levenstein distance before text_retriever (lev_retriever?)
* train bart for qa/facts
* train your own retriever

* Why is everything interpreted as "hello" or "hi"? You need a better retriever
  - Change retriever with the one you liked


* allow {variable} to be interpreted as code/call for another task (at least add tests)
* allow some type of introspection

* finish config
 - add hotwords to config.json
* upload to github, with tests and logs
* validate the user code (is REMEMBR spelled correctly?)

* should yes/no filter be in retriever instead of knowledge?

* Create interfaces for google voice, other apis
* A goal oriented bot would scan all the rules to find how to obtain the goal.
  The user can be simulated using a generative model for dialogue.

* for yes/no or limited choice questions there should not be ambiguity. The machine should match the closest item and
  if there is no item close enough ask again.


* New voice! It's ridiculous to have to have a memory leak from picotts
    - Use fairseq voices

* why is Alberto not recognized as a name by the retriever? need a better retriever than MSMARCO distill
* Working memory should really be working knowledge
* refactor BackwardInference

!* make it so if the user does not know the answer, one can continue inference?
   - Or should you try to do the inference first??
!* Implement a standard sign for code. Should it be '''> ?
!* Implement FORGET (the whole Fact should disappear from Knowledge)


* Do not allow arbitrary input (at least for voice)
* Working memory is unnecessarily complicated. It can just contain the story and some method to automatically fill it.
!* Why did it say "no" on "can you please add bananas to the shopping list?"
* Better QA for yes/no question (maybe add SNLI to qa?)
* Add math expressions to fact-checker (some, any, every)
* USER REQUEST: Multiple items to the shopping list in one go: apples AND bananas AND vegetables
* create tests for voice
* Parser should allow for empty lines within rules
* Implement Server with HTML page (docker-compose up)
* Refactor code and clean up

* Investigate interplay btw substitutions and already_matched
  - Maybe one can avoid having same answer for btw same question and same depth (and same rule)
* Say "This is true" or "this is false" if a statement matches (My name is Alberto -> True)
* working memory only within the same level of rules with same activation
  GET WORKING MEMORY FOR FACTS WORKING WITH SHOPPING LIST!!

/* Add working memory for python-space
    - Maybe exclude WM answer if it is the same as the prior answer
/* Use entailment to make generated qa more accurate
    /- Upload qa system to huggingface and pip
    /-**** Use conversation_qa -> refactor qa.py
